# Скопируйте этот файл в .env.openai и подставьте свой ключ OpenAI.
# Команда: cp env.openai.example .env.openai
# Затем откройте .env.openai и замените your-openai-key-here на ваш ключ.

PAPAYU_LLM_API_URL=https://api.openai.com/v1/chat/completions
PAPAYU_LLM_API_KEY=your-openai-key-here
PAPAYU_LLM_MODEL=gpt-4o-mini

# Строгий JSON (OpenAI Structured Outputs): добавляет response_format с JSON Schema.
# Работает с OpenAI; Ollama и др. могут не поддерживать — не задавать или =0.
# PAPAYU_LLM_STRICT_JSON=1

# memory_patch: 0 (по умолчанию) — игнорировать; 1 — применять по whitelist.
# PAPAYU_MEMORY_AUTOPATCH=0

# EOL: keep (по умолчанию) — не менять; lf — нормализовать \r\n→\n, trailing newline.
# PAPAYU_NORMALIZE_EOL=lf

# LLM: температура 0 (детерминизм), max_tokens 16384 (авто-кэп при input>80k → 4096).
# PAPAYU_LLM_TEMPERATURE=0
# PAPAYU_LLM_MAX_TOKENS=16384

# Таймаут запроса к LLM (сек).
# PAPAYU_LLM_TIMEOUT_SEC=90

# Трассировка: PAPAYU_TRACE=1 → пишет в .papa-yu/traces/<trace_id>.json (без raw_content по умолчанию).
# PAPAYU_TRACE=1
# PAPAYU_TRACE_RAW=1 — сохранять raw_content (с маскировкой sk-/Bearer)

# Контекст-диета: max 8 файлов, 20k на файл, 120k total.
# PAPAYU_CONTEXT_MAX_FILES=8
# PAPAYU_CONTEXT_MAX_FILE_CHARS=20000
# PAPAYU_CONTEXT_MAX_TOTAL_CHARS=120000
